{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s_qNSzzyaCbD"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "id": "jmjh290raIky"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2KYy4RoQolnm"
   },
   "source": [
    "# How to read a file that is stored in Google Drive\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g7eUJBUVo-U5",
    "outputId": "2f202e96-0982-42e2-ef81-4f971f401262"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RqicsCkOovGi"
   },
   "source": [
    "#Listing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oIra0i-zp_76",
    "outputId": "996c2b50-3a32-4912-c24a-b9a5ec96472f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " base.txt\t\t\t pietonsimage\n",
      " cnn.ipynb\t\t\t regressionlineaire.ipynb\n",
      "'Copie de WR.ipynb'\t\t'regressionlineairePEIP2 (1).ipynb'\n",
      " databaseC.csv\t\t\t regressionlineairePEIP2.ipynb\n",
      " LSTMtoRicardoPrediction.ipynb\t Untitled0.ipynb\n",
      " neuralneuronnenetwork.ipynb\t Untitled1.ipynb\n",
      " nmt_with_attention.ipynb\t WO_seq2seq_with_attention.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls \"./drive/My Drive/Colab Notebooks/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rQGtHqyxmvdl",
    "outputId": "cc854c95-492b-4667-c758-4194f1a0ea73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "import math\n",
    "\n",
    "#import tensorflow.compat.v1 as tf\n",
    "#import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "#tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BncMBj3dm2gG"
   },
   "source": [
    "# Parsing the files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QYgDRuwpjq6n"
   },
   "source": [
    "The parsing functions : They are taken from the Alafate Abulimiti project (https://github.com/AlafateABULIMITI/PRD) . We can skip this part.... We assume they are ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "064BA3y8m75x"
   },
   "outputs": [],
   "source": [
    "\n",
    "def saveLinewithC(line):\n",
    "        \"\"\"\n",
    "        Supplement function to build the different sets of the seq2seq model.\n",
    "\n",
    "        :param line: one line of the csv file\n",
    "        :return: ptimes_list, solved_list.\n",
    "\n",
    "        ptimes_list: the sequence with processing time and completion time.\n",
    "        solved_list: the binary sequence that can indicate the window.\n",
    "        \"\"\"\n",
    "        ptimes = line[0].split(' ')\n",
    "        ptimes_list = []\n",
    "        for k in range(1, len(ptimes), 4):\n",
    "            ptimes_list.append(\n",
    "                [int(float(ptimes[k])), int(float(ptimes[k + 1])), int(float(ptimes[k + 2])),\n",
    "                 int(float(ptimes[k + 3]))])\n",
    "        solved_list = list(map(int, line[1]))\n",
    "\n",
    "        return ptimes_list, solved_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "kTvckqu8nDmf"
   },
   "outputs": [],
   "source": [
    "\n",
    "def divideDatawithC(size, num_instance):\n",
    "        \"\"\"\n",
    "        Function can divide the data into 3 part: Training set, Test set and Validation set.\n",
    "\n",
    "        :param txtfile: the path of the database txt file.\n",
    "        :param size: size of the sequence\n",
    "        :return: X_train, y_train, X_test, y_test, X_validation, y_validation\n",
    "        X_train: Training set which have the initial sequence with processing time and completion time.\n",
    "        y_train: Training set which have the binary sequnece that can indicate the window.\n",
    "        X_test: Test set which have the initial sequence with processing time and completion time.\n",
    "        y_test: Test set which have the binary sequnece that can indicate the window.\n",
    "        X_validation: Validation set which have the initial sequence with processing time and completion time.\n",
    "        y_validation: Validation set which have the binary sequnece that can indicate the window.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"num_instance: \" + str(num_instance))\n",
    "        num_ins_test = int(num_instance * 0.2)\n",
    "        num_ins_validation = num_ins_test\n",
    "        num_ins_train = num_instance - num_ins_test * 2\n",
    "        X_train = []\n",
    "        y_train = []\n",
    "        X_test = []\n",
    "        y_test = []\n",
    "        X_validation = []\n",
    "        y_validation = []\n",
    "        with open('./drive/My Drive/Colab Notebooks/databaseC.csv') as data:\n",
    "            reader = csv.reader(data)\n",
    "            dataSet = list(reader)\n",
    "            length = len(dataSet)\n",
    "            count = 0\n",
    "            for line in dataSet:\n",
    "                if len(line) == 1:\n",
    "                    line_per_instance = 0\n",
    "                    count = count + 1\n",
    "                    continue\n",
    "                line_per_instance += 1\n",
    "                if line_per_instance < 5: # limit number of sequences per instances to 5\n",
    "                  if count <= num_ins_train:\n",
    "                      ptimes_list, solved_list = saveLinewithC(line)\n",
    "                      X_train.append(ptimes_list)\n",
    "                      y_train.append(solved_list)\n",
    "                  if num_ins_train < count <= num_ins_train + num_ins_test:\n",
    "                      ptimes_list, solved_list = saveLinewithC(line)\n",
    "                      X_test.append(ptimes_list)\n",
    "                      y_test.append(solved_list)\n",
    "                  if num_ins_train + num_ins_test < count <= num_instance:\n",
    "                      ptimes_list, solved_list = saveLinewithC(line)\n",
    "                      X_validation.append(ptimes_list)\n",
    "                      y_validation.append(solved_list)\n",
    "        X_train = np.asarray(X_train)\n",
    "        y_train = np.asarray(y_train)\n",
    "        y_train = np.reshape(y_train, (len(y_train), size, 1))\n",
    "        X_test = np.asarray(X_test)\n",
    "        y_test = np.asarray(y_test)\n",
    "        y_test = np.reshape(y_test, (len(y_test), size, 1))\n",
    "        X_validation = np.asarray(X_validation)\n",
    "        y_validation = np.asarray(y_validation)\n",
    "        y_validation = np.reshape(y_validation, (len(y_validation), size, 1))\n",
    "        return X_train, y_train, X_test, y_test, X_validation, y_validation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FT_OPCObnGnf"
   },
   "source": [
    "# Let us read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SgJHPfUMnKlc",
    "outputId": "6c586507-48ab-448f-bec9-567e1f4f105c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_instance: 4448\n",
      "X_train shape :  (10670, 100, 4)\n",
      " =>  [ 1 30  1 31]\n",
      "Y_train shape :  (10670, 100, 1)\n",
      " =>  [0]\n",
      "X_test shape :  (3552, 100, 4)\n",
      " =>  [ 1 14  1 15]\n",
      "X_validation shape :  (3553, 100, 4)\n",
      " =>  [ 1 19  1 20]\n",
      "8.534854799509048\n"
     ]
    }
   ],
   "source": [
    "num_instance = 4448 # num of instances, maximum 4448 by default\n",
    "jobs_size = 100 # size of jobs = size of input \n",
    "\n",
    "X_train, Y_train, X_test, Y_test, X_validation,Y_validation=divideDatawithC(jobs_size,num_instance)\n",
    "print(\"X_train shape : \", X_train.shape)\n",
    "print(\" => \", X_train[0,0])\n",
    "print(\"Y_train shape : \",Y_train.shape)\n",
    "print(\" => \", Y_train[0,0])\n",
    "X_train=tf.cast(X_train,dtype=tf.float32)\n",
    "Y_train=tf.cast(Y_train,dtype=tf.float32)\n",
    "\n",
    "print(\"X_test shape : \", X_test.shape)\n",
    "print(\" => \", X_test[0,0])\n",
    "\n",
    "print(\"X_validation shape : \", X_validation.shape)\n",
    "print(\" => \", X_validation[0,0])\n",
    "\n",
    "mean1=1-np.mean(Y_train)\n",
    "pos_weight=mean1*10\n",
    "#pos_weight=(jobs_size-mean1)+1\n",
    "#pos_weight=1.5+(Y_train.shape[0]*Y_train.shape[1]/np.sum(Y_train))\n",
    "#pos_weight=1+(1-np.mean(Y_train))+8.2  ###Why this value ???\n",
    "print(pos_weight)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J0Qjg6vuaHNt"
   },
   "source": [
    "# Neural machine translation with attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gb7P7WRcmCpQ"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AOpGoE2T-YXS"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/text/nmt_with_attention\">\n",
    "    <img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />\n",
    "    View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/text/nmt_with_attention.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
    "    Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/text/nmt_with_attention.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n",
    "    View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/text/nmt_with_attention.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RUvVcu-iqA3U"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgCLkfv5uO3d"
   },
   "source": [
    "### Create a tf.data dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TqHsArVZ3jFS",
    "outputId": "cb341ac1-002a-4df7-f5e6-08b899398d21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10670\n",
      "166\n",
      "1024\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 2\n",
    "input_tensor_train=X_train\n",
    "target_tensor_train=Y_train\n",
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "print(BUFFER_SIZE)\n",
    "BATCH_SIZE = 2**6\n",
    "steps_per_epoch = BUFFER_SIZE//BATCH_SIZE\n",
    "print(steps_per_epoch)\n",
    "unitsenc = 2**10 #128\n",
    "attentionembeddingdim=unitsenc\n",
    "unitsdec = attentionembeddingdim\n",
    "print(unitsenc)\n",
    "vocab_tar_size = 1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qc6-NK1GtWQt",
    "outputId": "349c7631-2ac8-4149-c63f-1c80dd2b53f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "(64, 100, 4) (64, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "#tf.enable_eager_execution()\n",
    "#tf.enable_eager_execution()\n",
    "\n",
    "print(tf.executing_eagerly())\n",
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "print(example_input_batch.shape, example_target_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNfHIF71ulLu"
   },
   "source": [
    "## Write the encoder and decoder model\n",
    "\n",
    "Implement an encoder-decoder model with attention which you can read about in the TensorFlow [Neural Machine Translation (seq2seq) tutorial](https://github.com/tensorflow/nmt). This example uses a more recent set of APIs. This notebook implements the [attention equations](https://github.com/tensorflow/nmt#background-on-the-attention-mechanism) from the seq2seq tutorial. The following diagram shows that each input words is assigned a weight by the attention mechanism which is then used by the decoder to predict the next word in the sentence. The below picture and formulas are an example of attention mechanism from [Luong's paper](https://arxiv.org/abs/1508.04025v5). \n",
    "\n",
    "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_mechanism.jpg\" width=\"500\" alt=\"attention mechanism\">\n",
    "\n",
    "The input is put through an encoder model which gives us the encoder output of shape *(batch_size, max_length, hidden_size)* and the encoder hidden state of shape *(batch_size, hidden_size)*.\n",
    "\n",
    "Here are the equations that are implemented:\n",
    "\n",
    "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_equation_0.jpg\" alt=\"attention equation 0\" width=\"800\">\n",
    "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_equation_1.jpg\" alt=\"attention equation 1\" width=\"800\">\n",
    "\n",
    "This tutorial uses [Bahdanau attention](https://arxiv.org/pdf/1409.0473.pdf) for the encoder. Let's decide on notation before writing the simplified form:\n",
    "\n",
    "* FC = Fully connected (dense) layer\n",
    "* EO = Encoder output\n",
    "* H = hidden state\n",
    "* X = input to the decoder\n",
    "\n",
    "And the pseudo-code:\n",
    "\n",
    "* `score = FC(tanh(FC(EO) + FC(H)))`\n",
    "* `attention weights = softmax(score, axis = 1)`. Softmax by default is applied on the last axis but here we want to apply it on the *1st axis*, since the shape of score is *(batch_size, max_length, hidden_size)*. `Max_length` is the length of our input. Since we are trying to assign a weight to each input, softmax should be applied on that axis.\n",
    "* `context vector = sum(attention weights * EO, axis = 1)`. Same reason as above for choosing axis as 1.\n",
    "* `embedding output` = The input to the decoder X is passed through an embedding layer.\n",
    "* `merged vector = concat(embedding output, context vector)`\n",
    "* This merged vector is then given to the GRU\n",
    "\n",
    "The shapes of all the vectors at each step have been specified in the comments in the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "nZ2rI24i3jFg"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "  def __init__(self, enc_units, batch_sz):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.enc_units = enc_units\n",
    "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform'\n",
    "                                   )\n",
    "\n",
    "  def call(self, x, hidden):\n",
    "    output, state = self.gru(x, initial_state = hidden)\n",
    "    return output, state\n",
    "\n",
    "  def initialize_hidden_state(self):\n",
    "    return tf.zeros((self.batch_sz ,self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "60gSVh05Jl6l",
    "outputId": "3a4c54f8-fd03-4390-b624-eacc4f622815"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (64, 100, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(unitsenc, BATCH_SIZE)\n",
    "\n",
    "# sample input\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "umohpBN2OM94"
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, units):\n",
    "    super(BahdanauAttention, self).__init__()\n",
    "    self.W1 = tf.keras.layers.Dense(units)\n",
    "    self.W2 = tf.keras.layers.Dense(units)\n",
    "    self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "  def call(self, query, values):\n",
    "    # query hidden state shape == (batch_size, hidden size)\n",
    "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "    # values shape == (batch_size, max_len, hidden size)\n",
    "    # we are doing this to broadcast addition along the time axis to calculate the score\n",
    "    query_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "    # score shape == (batch_size, max_length, 1)\n",
    "    # we get 1 at the last axis because we are applying score to self.V\n",
    "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "    score = self.V(tf.nn.tanh(\n",
    "        self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "    # attention_weights shape == (batch_size, max_length, 1)\n",
    "    attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "    # context_vector shape after sum == (batch_size, hidden_size)\n",
    "    context_vector = attention_weights * values\n",
    "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "    return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k534zTHiDjQU",
    "outputId": "3f0d634f-61d1-4a7f-d2a5-f3b0b1827756"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (64, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (64, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "attention_layer = BahdanauAttention(attentionembeddingdim)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "yJ_B3mhW3jFk"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "  def __init__(self, dec_units, batch_sz):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.dec_units = dec_units\n",
    "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "    #modif romain pour que le décodeur renvoie un taux de confiance\n",
    "    self.fc = tf.keras.layers.Dense(vocab_tar_size,activation='sigmoid')\n",
    "    \n",
    "    #code original\n",
    "    #self.fc = tf.keras.layers.Dense(1)\n",
    "    \n",
    "\n",
    "    # used for attention\n",
    "    self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "  def call(self, hidden, enc_output):\n",
    "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "    \n",
    "    x = tf.concat([tf.expand_dims(context_vector, 1), tf.expand_dims(hidden, 1)], axis=-1)\n",
    "\n",
    "    # passing the concatenated vector to the GRU\n",
    "    output, state = self.gru(x)\n",
    "\n",
    "    # output shape == (batch_size * 1, hidden_size)\n",
    "    output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "    # output shape == (batch_size, vocab)\n",
    "    x = self.fc(output)\n",
    "\n",
    "    return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P5UY8wko3jFp",
    "outputId": "6a692d8b-830a-4932-9440-1b4be308b6eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (64, 1)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(unitsdec, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ch_71VbIRfK"
   },
   "source": [
    "## Define the optimizer and the loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GcpjUQcbjet7"
   },
   "source": [
    "Binary cross entropy from tensorflow' source code in order to modify the loss function directly (return value from nn_sigmoid_cross_entropy_with_logits function)\n",
    "\n",
    "links of the code below with doc : \n",
    "https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/keras/losses.py#L348-L406\n",
    "https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/keras/backend.py#L4585-L4615\n",
    "https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/ops/nn_impl.py#L192-L239"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "nz-uFfFX9B_I"
   },
   "outputs": [],
   "source": [
    "import six\n",
    "\n",
    "from tensorflow.python.distribute import distribution_strategy_context\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.framework import smart_cond\n",
    "from tensorflow.python.framework import tensor_util\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.utils import losses_utils\n",
    "from tensorflow.python.keras.utils import tf_utils\n",
    "from tensorflow.python.keras.utils.generic_utils import deserialize_keras_object\n",
    "from tensorflow.python.keras.utils.generic_utils import serialize_keras_object\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops import nn\n",
    "from tensorflow.python.ops.losses import losses_impl\n",
    "from tensorflow.python.ops.losses import util as tf_losses_util\n",
    "from tensorflow.python.util.tf_export import keras_export\n",
    "from tensorflow.tools.docs import doc_controls\n",
    "from tensorflow.python.ops import nn_ops\n",
    "\n",
    "class Loss(object):\n",
    "  def __init__(self, reduction=losses_utils.ReductionV2.AUTO, name=None):\n",
    "    losses_utils.ReductionV2.validate(reduction)\n",
    "    self.reduction = reduction\n",
    "    self.name = name\n",
    "\n",
    "  def __call__(self, y_true, y_pred, sample_weight=None):\n",
    "    scope_name = 'lambda' if self.name == '<lambda>' else self.name\n",
    "    graph_ctx = tf_utils.graph_context_for_symbolic_tensors(\n",
    "        y_true, y_pred, sample_weight)\n",
    "    with K.name_scope(scope_name or self.__class__.__name__), graph_ctx:\n",
    "      losses = self.call(y_true, y_pred)\n",
    "      return losses_utils.compute_weighted_loss(\n",
    "          losses, sample_weight, reduction=self._get_reduction())\n",
    "          \n",
    "  def _get_reduction(self):\n",
    "      \"\"\"Handles `AUTO` reduction cases and returns the reduction value.\"\"\"\n",
    "      if distribution_strategy_context.has_strategy() and (\n",
    "          self.reduction == losses_utils.ReductionV2.AUTO or\n",
    "          self.reduction == losses_utils.ReductionV2.SUM_OVER_BATCH_SIZE):\n",
    "        raise ValueError(\n",
    "            'Please use `tf.keras.losses.Reduction.SUM` or '\n",
    "            '`tf.keras.losses.Reduction.NONE` for loss reduction when losses are '\n",
    "            'used with `tf.distribute.Strategy` outside of the built-in training '\n",
    "            'loops. You can implement '\n",
    "            '`tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE` using global batch '\n",
    "            'size like:\\n```\\nwith strategy.scope():\\n'\n",
    "            '    loss_obj = tf.keras.losses.CategoricalCrossentropy('\n",
    "            'reduction=tf.keras.losses.Reduction.NONE)\\n....\\n'\n",
    "            '    loss = tf.reduce_sum(loss_obj(labels, predictions)) * '\n",
    "            '(1. / global_batch_size)\\n```\\nPlease see '\n",
    "            'https://www.tensorflow.org/tutorials/distribute/custom_training'\n",
    "            ' for more details.')\n",
    "\n",
    "      if self.reduction == losses_utils.ReductionV2.AUTO:\n",
    "        return losses_utils.ReductionV2.SUM_OVER_BATCH_SIZE\n",
    "      return self.reduction\n",
    "\n",
    "\n",
    "class LossFunctionWrapper(Loss):\n",
    "  def __init__(self,\n",
    "               fn,\n",
    "               reduction=losses_utils.ReductionV2.AUTO,\n",
    "               name=None,\n",
    "               **kwargs):\n",
    "    super(LossFunctionWrapper, self).__init__(reduction=reduction, name=name)\n",
    "    self.fn = fn\n",
    "    self._fn_kwargs = kwargs\n",
    "\n",
    "  def call(self, y_true, y_pred):\n",
    "    if tensor_util.is_tensor(y_pred) and tensor_util.is_tensor(y_true):\n",
    "      y_pred, y_true = tf_losses_util.squeeze_or_expand_dimensions(\n",
    "          y_pred, y_true)\n",
    "    return self.fn(y_true, y_pred, **self._fn_kwargs)\n",
    "\n",
    "  def get_config(self):\n",
    "    config = {}\n",
    "    for k, v in six.iteritems(self._fn_kwargs):\n",
    "      config[k] = K.eval(v) if tf_utils.is_tensor_or_variable(v) else v\n",
    "    base_config = super(LossFunctionWrapper, self).get_config()\n",
    "    return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "def nn_sigmoid_cross_entropy_with_logits(\n",
    "    _sentinel=None,\n",
    "    labels=None,\n",
    "    logits=None,\n",
    "    name=None):\n",
    "  #nn_ops._ensure_xent_args(\"sigmoid_cross_entropy_with_logits\", _sentinel,\n",
    "  #                         labels, logits)\n",
    "\n",
    "  #logits = ops.convert_to_tensor(logits, name=\"logits\")\n",
    "  #labels = ops.convert_to_tensor(labels, name=\"labels\")\n",
    "  #with ops.name_scope(name, \"logistic_loss\", [logits, labels]) as name:\n",
    "  #  logits = ops.convert_to_tensor(logits, name=\"logits\")\n",
    "  #  labels = ops.convert_to_tensor(labels, name=\"labels\")\n",
    "  #  try:\n",
    "  #    labels.get_shape().merge_with(logits.get_shape())\n",
    "  #  except ValueError:\n",
    "  #    raise ValueError(\"logits and labels must have the same shape (%s vs %s)\" %\n",
    "  #                     (logits.get_shape(), labels.get_shape()))\n",
    "\n",
    "    \n",
    "    ####Code de yaniss : pas de softmax #######\n",
    "    #ratio_1 = 1.8  # les 1 pésent 0.2\n",
    "    #ratio_0 = 1.2  # les 0 pésent 0.8\n",
    "    \n",
    "    #zeros = array_ops.zeros_like(logits, dtype=logits.dtype)\n",
    "    #cond = (logits >= zeros)\n",
    "    #relu_logits = array_ops.where(cond, logits, zeros)\n",
    "    #neg_abs_logits = array_ops.where(cond, -logits, logits)\n",
    "\n",
    "    #return math_ops.add(\n",
    "    #    ratio_0 * (relu_logits - logits * labels),\n",
    "    #    math_ops.log1p(math_ops.exp(neg_abs_logits)) * ((ratio_1-ratio_0) * labels + ratio_0),\n",
    "    #    name=name)\n",
    "    ####Fin Code de yaniss : pas de softmax #######\n",
    "\n",
    "\n",
    "    # ---------------------------------------------------------------------------\n",
    "    # CODE MODIFIED HERE !!!\n",
    "\n",
    "    ####Code Normal  #######\n",
    "    #return math_ops.add(\n",
    "    #    -labels * math_ops.log1p(logits),\n",
    "    #    -(1-labels) * math_ops.log1p(1-logits),\n",
    "    #    name=name)\n",
    "    ####Fin Code Normal  #######\n",
    "\n",
    "\n",
    "    ####Code de romain, la sortie du décodeur doit être entre 0 et 1 #######\n",
    "  #logits = ops.convert_to_tensor(logits, name=\"logits\")\n",
    "  #labels = ops.convert_to_tensor(labels, name=\"labels\")\n",
    "\n",
    "  #zeros = array_ops.zeros_like(logits, dtype=logits.dtype)\n",
    "  #cond = (logits >= zeros)\n",
    "  #relu_logits = array_ops.where(cond, logits, zeros)\n",
    "  #neg_abs_logits = array_ops.where(cond, -logits, logits)\n",
    "  #return math_ops.add(  relu_logits - logits * labels, math_ops.log1p(math_ops.exp(neg_abs_logits)),name=name)  \n",
    "\n",
    "  #pos_weight=1+math_ops.mean(labels)\n",
    "  log_weight = 1 + (pos_weight - 1) * labels\n",
    "  return math_ops.add(  (1 - labels) * logits, log_weight * (math_ops.log1p(math_ops.exp(-math_ops.abs(logits))) +\n",
    "  nn_ops.relu(-logits)), name=name)\n",
    "  #return math_ops.add(\n",
    "  #      -labels * math_ops.log1p(logits),\n",
    "  #      -(1-labels) * math_ops.log1p(1-logits),\n",
    "  #      name=name)\n",
    "  #ratio_1 = 0.2#1.8  # les 1 pésent 0.2\n",
    "  #ratio_0 = 0.8#1.2  # les 0 pésent 0.8\n",
    "  #logitsclip = tf.clip_by_value(logits, clip_value_min=0.1, clip_value_max=0.9)\n",
    "  #labelclip = tf.clip_by_value(labels, clip_value_min=0, clip_value_max=1)\n",
    "  #val1=labels * math_ops.log1p(logits)\n",
    "  #val1=-1*val1\n",
    "  #val0=(1-labels) * math_ops.log1p(1-logits)\n",
    "  #val0=-1*val0\n",
    "  #return val1+val0\n",
    "    #return math_ops.add(\n",
    "     #   (-1*labels * math_ops.log1p(logitsclip))*ratio_1,\n",
    "     #   (-1*(1-labels) * math_ops.log1p(1-logitsclip))*ratio_0,\n",
    "     #   name=name)\n",
    "    \n",
    "    \n",
    "    # --------------------------------------------------------------------------\n",
    "\n",
    "def K_binary_crossentropy(target, output, from_logits=False):\n",
    "  return nn_sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n",
    "  #if not from_logits:\n",
    "  #  if (isinstance(output, (ops.EagerTensor, variables_module.Variable)) or\n",
    "  #      output.op.type != 'Sigmoid'):\n",
    "  #    epsilon_ = _constant_to_tensor(epsilon(), output.dtype.base_dtype)\n",
    "  #    output = clip_ops.clip_by_value(output, epsilon_, 1. - epsilon_)\n",
    "\n",
    "      # Compute cross entropy from probabilities.\n",
    "  #    bce = target * math_ops.log(output + epsilon())\n",
    "  #    bce += (1 - target) * math_ops.log(1 - output + epsilon())\n",
    "  #    return -bce\n",
    "  #  else:\n",
    "  #    assert len(output.op.inputs) == 1\n",
    "  #    output = output.op.inputs[0]\n",
    "  \n",
    "\n",
    "def binary_crossentropy(y_true, y_pred, from_logits=False, label_smoothing=0):  # pylint: disable=missing-docstring\n",
    "  #y_pred = ops.convert_to_tensor(y_pred)\n",
    "  y_true = math_ops.cast(y_true, y_pred.dtype)\n",
    "  #label_smoothing = ops.convert_to_tensor(label_smoothing, dtype=K.floatx())\n",
    "\n",
    "  #def _smooth_labels():\n",
    "  #  return y_true * (1.0 - label_smoothing) + 0.5 * label_smoothing\n",
    "\n",
    "  #y_true = smart_cond.smart_cond(label_smoothing,\n",
    "  #                               _smooth_labels, lambda: y_true)\n",
    "  return K.mean(\n",
    "      tf.nn.weighted_cross_entropy_with_logits(labels=y_true, logits=y_pred,pos_weight=pos_weight), axis=-1)\n",
    "      #nn_sigmoid_cross_entropy_with_logits(labels=y_true, logits=y_pred), axis=-1)\n",
    "\n",
    "class BinaryCrossentropy(LossFunctionWrapper):\n",
    "  def __init__(self,\n",
    "               from_logits=False,\n",
    "               label_smoothing=0,\n",
    "               reduction=losses_utils.ReductionV2.AUTO,\n",
    "               name='binary_crossentropy'):\n",
    "    super(BinaryCrossentropy, self).__init__(\n",
    "        binary_crossentropy,\n",
    "        name=name,\n",
    "        reduction=reduction,\n",
    "        from_logits=from_logits,\n",
    "        label_smoothing=label_smoothing)\n",
    "    self.from_logits = from_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "WmTHr5iV3jFr"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.ops import math_ops\n",
    "\n",
    "def custom_loss_function(actual, predicted):\n",
    "  return -actual * math_ops.log1p(predicted) - (1-actual) * math_ops.log1p(1-predicted)\n",
    "\n",
    "#optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(0.0005)\n",
    "\n",
    "# definition of differents loss function\n",
    "loss_object_0 = tf.keras.losses.BinaryCrossentropy(\n",
    "    from_logits=True, reduction='none') # Tensorflow's\n",
    "\n",
    "loss_object_1 = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none') # Tensorflow's\n",
    "\n",
    "loss_object_2 = BinaryCrossentropy(from_logits=True, reduction='none') # Mine\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  #mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object_2(real, pred)\n",
    "\n",
    "  #mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  #loss_ *= mask\n",
    "\n",
    "  return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DMVWzzsfNl4e"
   },
   "source": [
    "## Checkpoints (Object-based saving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Zj8bXQTgNwrF"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpObfY22IddU"
   },
   "source": [
    "## Training\n",
    "\n",
    "1. Pass the *input* through the *encoder* which return *encoder output* and the *encoder hidden state*.\n",
    "2. The encoder output, encoder hidden state and the decoder input (which is the *start token*) is passed to the decoder.\n",
    "3. The decoder returns the *predictions* and the *decoder hidden state*.\n",
    "4. The decoder hidden state is then passed back into the model and the predictions are used to calculate the loss.\n",
    "5. Use *teacher forcing* to decide the next input to the decoder.\n",
    "6. *Teacher forcing* is the technique where the *target word* is passed as the *next input* to the decoder.\n",
    "7. The final step is to calculate the gradients and apply it to the optimizer and backpropagate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "sC9ArXSsVfqn"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "  loss = 0\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "\n",
    "    # Teacher forcing - feeding the target as the next input\n",
    "    for t in range(0, 100):\n",
    "      # passing enc_output to the decoder\n",
    "      predictions, dec_hidden, _ = decoder(dec_hidden, enc_output)\n",
    "\n",
    "      loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "      # using teacher forcing\n",
    "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "  batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "\n",
    "  optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "  return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "ubQtDM97PlRr"
   },
   "outputs": [],
   "source": [
    "def eval_validation(inp, targ):\n",
    "  \"\"\"\n",
    "  Evaluate the test sequences\n",
    "  \"\"\"\n",
    "  loss = 0\n",
    "  enc_hidden = encoder.initialize_hidden_state()\n",
    "  enc_out, enc_hidden = encoder(inp, enc_hidden)\n",
    "  dec_hidden = enc_hidden\n",
    "  \n",
    "\n",
    "  for t in range(len(inp[0])):\n",
    "    predictions, dec_hidden, attention_weights = decoder(dec_hidden, enc_out)\n",
    "    loss += loss_function(targ[:, t], predictions)\n",
    "    \n",
    "  return loss / int(targ.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "PCC-mPLyxk64"
   },
   "outputs": [],
   "source": [
    "\n",
    "dataset_test = tf.data.Dataset.from_tensor_slices((X_test, Y_test)).shuffle(BUFFER_SIZE)\n",
    "dataset_test = dataset.batch(BATCH_SIZE, drop_remainder=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ddefjBMa3jF0",
    "outputId": "d6edb9d5-044b-4520-cab9-95ac517931ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 1.4283\n",
      "Epoch 1 Batch 1 Loss 1.4599\n",
      "Epoch 1 Batch 2 Loss 1.4515\n",
      "Epoch 1 Batch 3 Loss 1.4490\n",
      "Epoch 1 Batch 4 Loss 1.4498\n",
      "Epoch 1 Batch 5 Loss 1.4213\n",
      "Epoch 1 Batch 6 Loss 1.4214\n",
      "Epoch 1 Batch 7 Loss 1.4340\n",
      "Epoch 1 Batch 8 Loss 1.4259\n",
      "Epoch 1 Batch 9 Loss 1.4353\n",
      "Epoch 1 Batch 10 Loss 1.4309\n",
      "Epoch 1 Batch 11 Loss 1.3994\n",
      "Epoch 1 Batch 12 Loss 1.4176\n",
      "Epoch 1 Batch 13 Loss 1.3994\n",
      "Epoch 1 Batch 14 Loss 1.4155\n",
      "Epoch 1 Batch 15 Loss 1.4077\n",
      "Epoch 1 Batch 16 Loss 1.4172\n",
      "Epoch 1 Batch 17 Loss 1.4114\n",
      "Epoch 1 Batch 18 Loss 1.4211\n",
      "Epoch 1 Batch 19 Loss 1.4140\n",
      "Epoch 1 Batch 20 Loss 1.4126\n",
      "Epoch 1 Batch 21 Loss 1.4207\n",
      "Epoch 1 Batch 22 Loss 1.4095\n",
      "Epoch 1 Batch 23 Loss 1.4164\n",
      "Epoch 1 Batch 24 Loss 1.4104\n",
      "Epoch 1 Batch 25 Loss 1.4067\n",
      "Epoch 1 Batch 26 Loss 1.4076\n",
      "Epoch 1 Batch 27 Loss 1.4096\n",
      "Epoch 1 Batch 28 Loss 1.4049\n",
      "Epoch 1 Batch 29 Loss 1.4065\n",
      "Epoch 1 Batch 30 Loss 1.4062\n",
      "Epoch 1 Batch 31 Loss 1.4074\n",
      "Epoch 1 Batch 32 Loss 1.4161\n",
      "Epoch 1 Batch 33 Loss 1.3995\n",
      "Epoch 1 Batch 34 Loss 1.4131\n",
      "Epoch 1 Batch 35 Loss 1.4124\n",
      "Epoch 1 Batch 36 Loss 1.4095\n",
      "Epoch 1 Batch 37 Loss 1.4116\n",
      "Epoch 1 Batch 38 Loss 1.4033\n",
      "Epoch 1 Batch 39 Loss 1.4018\n",
      "Epoch 1 Batch 40 Loss 1.4360\n",
      "Epoch 1 Batch 41 Loss 1.4085\n",
      "Epoch 1 Batch 42 Loss 1.4054\n",
      "Epoch 1 Batch 43 Loss 1.4025\n",
      "Epoch 1 Batch 44 Loss 1.4037\n",
      "Epoch 1 Batch 45 Loss 1.4193\n",
      "Epoch 1 Batch 46 Loss 1.4264\n",
      "Epoch 1 Batch 47 Loss 1.4165\n",
      "Epoch 1 Batch 48 Loss 1.4109\n",
      "Epoch 1 Batch 49 Loss 1.3986\n",
      "Epoch 1 Batch 50 Loss 1.4166\n",
      "Epoch 1 Batch 51 Loss 1.4142\n",
      "Epoch 1 Batch 52 Loss 1.4216\n",
      "Epoch 1 Batch 53 Loss 1.4194\n",
      "Epoch 1 Batch 54 Loss 1.4150\n",
      "Epoch 1 Batch 55 Loss 1.4072\n",
      "Epoch 1 Batch 56 Loss 1.4169\n",
      "Epoch 1 Batch 57 Loss 1.4043\n",
      "Epoch 1 Batch 58 Loss 1.4044\n",
      "Epoch 1 Batch 59 Loss 1.4146\n",
      "Epoch 1 Batch 60 Loss 1.3978\n",
      "Epoch 1 Batch 61 Loss 1.4246\n",
      "Epoch 1 Batch 62 Loss 1.4036\n",
      "Epoch 1 Batch 63 Loss 1.4099\n",
      "Epoch 1 Batch 64 Loss 1.4181\n",
      "Epoch 1 Batch 65 Loss 1.4161\n",
      "Epoch 1 Batch 66 Loss 1.4244\n",
      "Epoch 1 Batch 67 Loss 1.4090\n",
      "Epoch 1 Batch 68 Loss 1.4051\n",
      "Epoch 1 Batch 69 Loss 1.4316\n",
      "Epoch 1 Batch 70 Loss 1.4038\n",
      "Epoch 1 Batch 71 Loss 1.4029\n",
      "Epoch 1 Batch 72 Loss 1.4027\n",
      "Epoch 1 Batch 73 Loss 1.4063\n",
      "Epoch 1 Batch 74 Loss 1.4139\n",
      "Epoch 1 Batch 75 Loss 1.4070\n",
      "Epoch 1 Batch 76 Loss 1.4185\n",
      "Epoch 1 Batch 77 Loss 1.4186\n",
      "Epoch 1 Batch 78 Loss 1.4118\n",
      "Epoch 1 Batch 79 Loss 1.4100\n",
      "Epoch 1 Batch 80 Loss 1.4098\n",
      "Epoch 1 Batch 81 Loss 1.4256\n",
      "Epoch 1 Batch 82 Loss 1.3905\n",
      "Epoch 1 Batch 83 Loss 1.3987\n",
      "Epoch 1 Batch 84 Loss 1.4133\n",
      "Epoch 1 Batch 85 Loss 1.4190\n",
      "Epoch 1 Batch 86 Loss 1.4156\n",
      "Epoch 1 Batch 87 Loss 1.4176\n",
      "Epoch 1 Batch 88 Loss 1.4046\n",
      "Epoch 1 Batch 89 Loss 1.4134\n",
      "Epoch 1 Batch 90 Loss 1.4199\n",
      "Epoch 1 Batch 91 Loss 1.4045\n",
      "Epoch 1 Batch 92 Loss 1.3915\n",
      "Epoch 1 Batch 93 Loss 1.4049\n",
      "Epoch 1 Batch 94 Loss 1.4064\n",
      "Epoch 1 Batch 95 Loss 1.3938\n",
      "Epoch 1 Batch 96 Loss 1.4031\n",
      "Epoch 1 Batch 97 Loss 1.4043\n",
      "Epoch 1 Batch 98 Loss 1.4122\n",
      "Epoch 1 Batch 99 Loss 1.4086\n",
      "Epoch 1 Batch 100 Loss 1.4156\n",
      "Epoch 1 Batch 101 Loss 1.4203\n",
      "Epoch 1 Batch 102 Loss 1.4320\n",
      "Epoch 1 Batch 103 Loss 1.4496\n",
      "Epoch 1 Batch 104 Loss 1.4676\n",
      "Epoch 1 Batch 105 Loss 1.4735\n",
      "Epoch 1 Batch 106 Loss 1.4851\n",
      "Epoch 1 Batch 107 Loss 1.4525\n",
      "Epoch 1 Batch 108 Loss 1.4550\n",
      "Epoch 1 Batch 109 Loss 1.4517\n",
      "Epoch 1 Batch 110 Loss 1.4532\n",
      "Epoch 1 Batch 111 Loss 1.4417\n",
      "Epoch 1 Batch 112 Loss 1.4727\n",
      "Epoch 1 Batch 113 Loss 1.4783\n",
      "Epoch 1 Batch 114 Loss 1.4693\n",
      "Epoch 1 Batch 115 Loss 1.4464\n",
      "Epoch 1 Batch 116 Loss 1.4709\n",
      "Epoch 1 Batch 117 Loss 1.4537\n",
      "Epoch 1 Batch 118 Loss 1.4635\n",
      "Epoch 1 Batch 119 Loss 1.4431\n",
      "Epoch 1 Batch 120 Loss 1.4815\n",
      "Epoch 1 Batch 121 Loss 1.4709\n",
      "Epoch 1 Batch 122 Loss 1.4578\n",
      "Epoch 1 Batch 123 Loss 1.4562\n",
      "Epoch 1 Batch 124 Loss 1.4602\n",
      "Epoch 1 Batch 125 Loss 1.4309\n",
      "Epoch 1 Batch 126 Loss 1.4627\n",
      "Epoch 1 Batch 127 Loss 1.4472\n",
      "Epoch 1 Batch 128 Loss 1.4455\n",
      "Epoch 1 Batch 129 Loss 1.4504\n",
      "Epoch 1 Batch 130 Loss 1.4757\n",
      "Epoch 1 Batch 131 Loss 1.4651\n",
      "Epoch 1 Batch 132 Loss 1.4790\n",
      "Epoch 1 Batch 133 Loss 1.4488\n",
      "Epoch 1 Batch 134 Loss 1.4504\n",
      "Epoch 1 Batch 135 Loss 1.4553\n",
      "Epoch 1 Batch 136 Loss 1.4447\n",
      "Epoch 1 Batch 137 Loss 1.4211\n",
      "Epoch 1 Batch 138 Loss 1.4455\n",
      "Epoch 1 Batch 139 Loss 1.4619\n",
      "Epoch 1 Batch 140 Loss 1.4521\n",
      "Epoch 1 Batch 141 Loss 1.4684\n",
      "Epoch 1 Batch 142 Loss 1.4545\n",
      "Epoch 1 Batch 143 Loss 1.4537\n",
      "Epoch 1 Batch 144 Loss 1.4529\n",
      "Epoch 1 Batch 145 Loss 1.4725\n",
      "Epoch 1 Batch 146 Loss 1.4529\n",
      "Epoch 1 Batch 147 Loss 1.4651\n",
      "Epoch 1 Batch 148 Loss 1.4472\n",
      "Epoch 1 Batch 149 Loss 1.4725\n",
      "Epoch 1 Batch 150 Loss 1.4545\n",
      "Epoch 1 Batch 151 Loss 1.4667\n",
      "Epoch 1 Batch 152 Loss 1.4733\n",
      "Epoch 1 Batch 153 Loss 1.4545\n",
      "Epoch 1 Batch 154 Loss 1.4627\n",
      "Epoch 1 Batch 155 Loss 1.4496\n",
      "Epoch 1 Batch 156 Loss 1.4406\n",
      "Epoch 1 Batch 157 Loss 1.4521\n",
      "Epoch 1 Batch 158 Loss 1.4570\n",
      "Epoch 1 Batch 159 Loss 1.4814\n",
      "Epoch 1 Batch 160 Loss 1.4692\n",
      "Epoch 1 Batch 161 Loss 1.4627\n",
      "Epoch 1 Batch 162 Loss 1.4496\n",
      "Epoch 1 Batch 163 Loss 1.4594\n",
      "Epoch 1 Batch 164 Loss 1.4586\n",
      "Epoch 1 Batch 165 Loss 1.4684\n",
      "Epoch 1 Loss 1.4308\n",
      "Time taken for 1 epoch 508.0863721370697 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 1.4586\n",
      "Epoch 2 Batch 1 Loss 1.4675\n",
      "Epoch 2 Batch 2 Loss 1.4349\n",
      "Epoch 2 Batch 3 Loss 1.4733\n",
      "Epoch 2 Batch 4 Loss 1.4594\n",
      "Epoch 2 Batch 5 Loss 1.4651\n",
      "Epoch 2 Batch 6 Loss 1.4586\n",
      "Epoch 2 Batch 7 Loss 1.4732\n",
      "Epoch 2 Batch 8 Loss 1.4496\n",
      "Epoch 2 Batch 9 Loss 1.4471\n",
      "Epoch 2 Batch 10 Loss 1.4496\n",
      "Epoch 2 Batch 11 Loss 1.4708\n",
      "Epoch 2 Batch 12 Loss 1.4814\n",
      "Epoch 2 Batch 13 Loss 1.4732\n",
      "Epoch 2 Batch 14 Loss 1.4634\n",
      "Epoch 2 Batch 15 Loss 1.4748\n",
      "Epoch 2 Batch 16 Loss 1.4577\n",
      "Epoch 2 Batch 17 Loss 1.4495\n",
      "Epoch 2 Batch 18 Loss 1.4381\n",
      "Epoch 2 Batch 19 Loss 1.4544\n",
      "Epoch 2 Batch 20 Loss 1.4503\n",
      "Epoch 2 Batch 21 Loss 1.4544\n",
      "Epoch 2 Batch 22 Loss 1.4592\n",
      "Epoch 2 Batch 23 Loss 1.4641\n",
      "Epoch 2 Batch 24 Loss 1.4591\n",
      "Epoch 2 Batch 25 Loss 1.4574\n",
      "Epoch 2 Batch 26 Loss 1.4509\n",
      "Epoch 2 Batch 27 Loss 1.4695\n",
      "Epoch 2 Batch 28 Loss 1.4652\n",
      "Epoch 2 Batch 29 Loss 1.4406\n",
      "Epoch 2 Batch 30 Loss 1.4523\n",
      "Epoch 2 Batch 31 Loss 1.4419\n",
      "Epoch 2 Batch 32 Loss 1.4605\n",
      "Epoch 2 Batch 33 Loss 1.4229\n",
      "Epoch 2 Batch 34 Loss 1.4625\n",
      "Epoch 2 Batch 35 Loss 1.4301\n",
      "Epoch 2 Batch 36 Loss 1.4197\n",
      "Epoch 2 Batch 37 Loss 1.4299\n",
      "Epoch 2 Batch 38 Loss 1.4329\n",
      "Epoch 2 Batch 39 Loss 1.4035\n",
      "Epoch 2 Batch 40 Loss 1.4048\n",
      "Epoch 2 Batch 41 Loss 1.4140\n",
      "Epoch 2 Batch 42 Loss 1.4212\n",
      "Epoch 2 Batch 43 Loss 1.4323\n",
      "Epoch 2 Batch 44 Loss 1.4093\n",
      "Epoch 2 Batch 45 Loss 1.4051\n",
      "Epoch 2 Batch 46 Loss 1.4159\n",
      "Epoch 2 Batch 47 Loss 1.4229\n",
      "Epoch 2 Batch 48 Loss 1.4114\n",
      "Epoch 2 Batch 49 Loss 1.4134\n",
      "Epoch 2 Batch 50 Loss 1.4201\n",
      "Epoch 2 Batch 51 Loss 1.4072\n",
      "Epoch 2 Batch 52 Loss 1.4106\n",
      "Epoch 2 Batch 53 Loss 1.4166\n",
      "Epoch 2 Batch 54 Loss 1.4212\n",
      "Epoch 2 Batch 55 Loss 1.4150\n",
      "Epoch 2 Batch 56 Loss 1.4304\n",
      "Epoch 2 Batch 57 Loss 1.4071\n",
      "Epoch 2 Batch 58 Loss 1.4154\n",
      "Epoch 2 Batch 59 Loss 1.3937\n",
      "Epoch 2 Batch 60 Loss 1.4120\n",
      "Epoch 2 Batch 61 Loss 1.4141\n",
      "Epoch 2 Batch 62 Loss 1.4074\n",
      "Epoch 2 Batch 63 Loss 1.4175\n",
      "Epoch 2 Batch 64 Loss 1.4172\n",
      "Epoch 2 Batch 65 Loss 1.4207\n",
      "Epoch 2 Batch 66 Loss 1.4059\n",
      "Epoch 2 Batch 67 Loss 1.4125\n",
      "Epoch 2 Batch 68 Loss 1.4048\n",
      "Epoch 2 Batch 69 Loss 1.4136\n",
      "Epoch 2 Batch 70 Loss 1.4172\n",
      "Epoch 2 Batch 71 Loss 1.4162\n",
      "Epoch 2 Batch 72 Loss 1.3960\n",
      "Epoch 2 Batch 73 Loss 1.4082\n",
      "Epoch 2 Batch 74 Loss 1.4042\n",
      "Epoch 2 Batch 75 Loss 1.4117\n",
      "Epoch 2 Batch 76 Loss 1.3929\n",
      "Epoch 2 Batch 77 Loss 1.4111\n",
      "Epoch 2 Batch 78 Loss 1.3980\n",
      "Epoch 2 Batch 79 Loss 1.4196\n",
      "Epoch 2 Batch 80 Loss 1.4133\n",
      "Epoch 2 Batch 81 Loss 1.4097\n",
      "Epoch 2 Batch 82 Loss 1.3996\n",
      "Epoch 2 Batch 83 Loss 1.3924\n",
      "Epoch 2 Batch 84 Loss 1.3931\n",
      "Epoch 2 Batch 85 Loss 1.4125\n",
      "Epoch 2 Batch 86 Loss 1.4233\n",
      "Epoch 2 Batch 87 Loss 1.3988\n",
      "Epoch 2 Batch 88 Loss 1.4049\n",
      "Epoch 2 Batch 89 Loss 1.4208\n",
      "Epoch 2 Batch 90 Loss 1.4091\n",
      "Epoch 2 Batch 91 Loss 1.4100\n",
      "Epoch 2 Batch 92 Loss 1.4213\n",
      "Epoch 2 Batch 93 Loss 1.3910\n",
      "Epoch 2 Batch 94 Loss 1.4047\n",
      "Epoch 2 Batch 95 Loss 1.3961\n",
      "Epoch 2 Batch 96 Loss 1.4119\n",
      "Epoch 2 Batch 97 Loss 1.4157\n",
      "Epoch 2 Batch 98 Loss 1.4125\n",
      "Epoch 2 Batch 99 Loss 1.4112\n",
      "Epoch 2 Batch 100 Loss 1.4095\n",
      "Epoch 2 Batch 101 Loss 1.4053\n",
      "Epoch 2 Batch 102 Loss 1.3972\n",
      "Epoch 2 Batch 103 Loss 1.4217\n",
      "Epoch 2 Batch 104 Loss 1.4127\n",
      "Epoch 2 Batch 105 Loss 1.4164\n",
      "Epoch 2 Batch 106 Loss 1.4212\n",
      "Epoch 2 Batch 107 Loss 1.4106\n",
      "Epoch 2 Batch 108 Loss 1.4128\n",
      "Epoch 2 Batch 109 Loss 1.4126\n",
      "Epoch 2 Batch 110 Loss 1.4127\n",
      "Epoch 2 Batch 111 Loss 1.4241\n",
      "Epoch 2 Batch 112 Loss 1.3860\n",
      "Epoch 2 Batch 113 Loss 1.4138\n",
      "Epoch 2 Batch 114 Loss 1.4070\n",
      "Epoch 2 Batch 115 Loss 1.4159\n",
      "Epoch 2 Batch 116 Loss 1.4068\n",
      "Epoch 2 Batch 117 Loss 1.4139\n",
      "Epoch 2 Batch 118 Loss 1.4210\n",
      "Epoch 2 Batch 119 Loss 1.4136\n",
      "Epoch 2 Batch 120 Loss 1.4037\n",
      "Epoch 2 Batch 121 Loss 1.4091\n",
      "Epoch 2 Batch 122 Loss 1.4181\n",
      "Epoch 2 Batch 123 Loss 1.4040\n",
      "Epoch 2 Batch 124 Loss 1.4065\n",
      "Epoch 2 Batch 125 Loss 1.4143\n",
      "Epoch 2 Batch 126 Loss 1.4182\n",
      "Epoch 2 Batch 127 Loss 1.4174\n",
      "Epoch 2 Batch 128 Loss 1.3986\n",
      "Epoch 2 Batch 129 Loss 1.4105\n",
      "Epoch 2 Batch 130 Loss 1.4005\n",
      "Epoch 2 Batch 131 Loss 1.3892\n",
      "Epoch 2 Batch 132 Loss 1.4155\n",
      "Epoch 2 Batch 133 Loss 1.3829\n",
      "Epoch 2 Batch 134 Loss 1.4158\n",
      "Epoch 2 Batch 135 Loss 1.4124\n",
      "Epoch 2 Batch 136 Loss 1.4074\n",
      "Epoch 2 Batch 137 Loss 1.3973\n",
      "Epoch 2 Batch 138 Loss 1.4049\n",
      "Epoch 2 Batch 139 Loss 1.3943\n",
      "Epoch 2 Batch 140 Loss 1.4008\n",
      "Epoch 2 Batch 141 Loss 1.4280\n",
      "Epoch 2 Batch 142 Loss 1.3963\n",
      "Epoch 2 Batch 143 Loss 1.4138\n",
      "Epoch 2 Batch 144 Loss 1.4177\n",
      "Epoch 2 Batch 145 Loss 1.4140\n",
      "Epoch 2 Batch 146 Loss 1.4167\n",
      "Epoch 2 Batch 147 Loss 1.4079\n",
      "Epoch 2 Batch 148 Loss 1.3910\n",
      "Epoch 2 Batch 149 Loss 1.4008\n",
      "Epoch 2 Batch 150 Loss 1.4146\n",
      "Epoch 2 Batch 151 Loss 1.4015\n",
      "Epoch 2 Batch 152 Loss 1.4144\n",
      "Epoch 2 Batch 153 Loss 1.3975\n",
      "Epoch 2 Batch 154 Loss 1.4159\n",
      "Epoch 2 Batch 155 Loss 1.4179\n",
      "Epoch 2 Batch 156 Loss 1.4002\n",
      "Epoch 2 Batch 157 Loss 1.4021\n",
      "Epoch 2 Batch 158 Loss 1.4075\n",
      "Epoch 2 Batch 159 Loss 1.4037\n",
      "Epoch 2 Batch 160 Loss 1.4092\n",
      "Epoch 2 Batch 161 Loss 1.4132\n",
      "Epoch 2 Batch 162 Loss 1.4122\n",
      "Epoch 2 Batch 163 Loss 1.3942\n",
      "Epoch 2 Batch 164 Loss 1.4086\n",
      "Epoch 2 Batch 165 Loss 1.4038\n",
      "Epoch 2 Loss 1.4200\n",
      "Time taken for 1 epoch 409.1098086833954 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ls_of_loss = []\n",
    "t_of_loss = []\n",
    "ls_of_loss_test = []\n",
    "t_of_loss_test = []\n",
    "\n",
    "temp = 0\n",
    "sum = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  enc_hidden = encoder.initialize_hidden_state()\n",
    "  total_loss = 0\n",
    "  total_loss_test = 0\n",
    "\n",
    "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "\n",
    "    sum += 1\n",
    "\n",
    "    # train data\n",
    "    batch_loss = train_step(inp, targ, enc_hidden)\n",
    "    total_loss += batch_loss\n",
    "    ls_of_loss.append(batch_loss)\n",
    "    t_of_loss.append(sum)\n",
    "\n",
    "    # test on validation data\n",
    "    if BATCH_SIZE * (temp+1) > len(X_test):\n",
    "      temp = 0\n",
    "\n",
    "    a = tf.cast(X_test[BATCH_SIZE * (temp) : BATCH_SIZE * (temp+1)],dtype=tf.float32)\n",
    "    b = Y_test[BATCH_SIZE * (temp) : BATCH_SIZE * (temp+1)]\n",
    "    batch_loss_test = eval_validation(a, b)\n",
    "    total_loss_test += batch_loss_test\n",
    "    ls_of_loss_test.append(batch_loss_test)\n",
    "    t_of_loss_test.append(sum)\n",
    "    \n",
    "    temp += 1\n",
    "\n",
    "    if batch % 1 == 0:\n",
    "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                   batch,\n",
    "                                                   batch_loss.numpy()))\n",
    "    #if batch >= 20:\n",
    "    #  break;\n",
    "  \n",
    "  # saving (checkpoint) the model every 2 epochs\n",
    "  if (epoch + 1) % 2 == 0:\n",
    "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "id": "g-Z6o08ZNwey",
    "outputId": "28c5b8c8-2b43-48fe-b449-578aab9f919f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graphics of loss over time\n",
    "\n",
    "fig = plt.figure(figsize=(5, 3))\n",
    "plt.plot(t_of_loss, ls_of_loss, 'b-')\n",
    "plt.plot(t_of_loss_test, ls_of_loss_test, 'r-')\n",
    "plt.xlabel('minibatch iteration')\n",
    "plt.ylabel('$\\\\xi$', fontsize=15)\n",
    "plt.title('Decrease of loss over backprop iteration')\n",
    "fig.subplots_adjust(bottom=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EbQpyYs13jF_",
    "outputId": "e130c5be-c13a-4fba-eb4e-b3b6be8e3690"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0.0014228] [0]\n",
      "1 [0.00069607] [0]\n",
      "2 [0.0001404] [0]\n",
      "3 [4.5467972e-05] [0]\n",
      "4 [2.7835355e-05] [0]\n",
      "5 [3.3967273e-05] [0]\n",
      "6 [7.302315e-05] [0]\n",
      "7 [0.00022707] [0]\n",
      "8 [0.00086531] [0]\n",
      "9 [0.00334551] [0]\n",
      "10 [0.01198577] [0]\n",
      "11 [0.03960031] [0]\n",
      "12 [0.11568321] [0]\n",
      "13 [0.25366476] [0]\n",
      "14 [0.37920624] [0]\n",
      "15 [0.44025606] [0]\n",
      "16 [0.4612371] [0]\n",
      "17 [0.4675218] [0]\n",
      "18 [0.46932238] [0]\n",
      "19 [0.46983153] [0]\n",
      "20 [0.469975] [0]\n",
      "21 [0.4700153] [0]\n",
      "22 [0.47002664] [0]\n",
      "23 [0.47002986] [0]\n",
      "24 [0.4700307] [0]\n",
      "25 [0.47003102] [0]\n",
      "26 [0.47003108] [0]\n",
      "27 [0.47003114] [0]\n",
      "28 [0.47003114] [0]\n",
      "29 [0.47003114] [0]\n",
      "30 [0.47003114] [0]\n",
      "31 [0.47003114] [0]\n",
      "32 [0.47003114] [0]\n",
      "33 [0.47003114] [0]\n",
      "34 [0.47003114] [0]\n",
      "35 [0.47003114] [0]\n",
      "36 [0.47003114] [0]\n",
      "37 [0.47003114] [0]\n",
      "38 [0.47003114] [0]\n",
      "39 [0.47003114] [0]\n",
      "40 [0.47003114] [0]\n",
      "41 [0.47003114] [0]\n",
      "42 [0.47003114] [0]\n",
      "43 [0.47003114] [0]\n",
      "44 [0.47003114] [0]\n",
      "45 [0.47003114] [0]\n",
      "46 [0.47003114] [0]\n",
      "47 [0.47003114] [0]\n",
      "48 [0.47003114] [0]\n",
      "49 [0.47003114] [1]\n",
      "50 [0.47003114] [1]\n",
      "51 [0.47003114] [1]\n",
      "52 [0.47003114] [1]\n",
      "53 [0.47003114] [1]\n",
      "54 [0.47003114] [1]\n",
      "55 [0.47003114] [1]\n",
      "56 [0.47003114] [1]\n",
      "57 [0.47003114] [1]\n",
      "58 [0.47003114] [1]\n",
      "59 [0.47003114] [1]\n",
      "60 [0.47003114] [1]\n",
      "61 [0.47003114] [1]\n",
      "62 [0.47003114] [1]\n",
      "63 [0.47003114] [0]\n",
      "64 [0.47003114] [0]\n",
      "65 [0.47003114] [0]\n",
      "66 [0.47003114] [0]\n",
      "67 [0.47003114] [0]\n",
      "68 [0.47003114] [0]\n",
      "69 [0.47003114] [0]\n",
      "70 [0.47003114] [0]\n",
      "71 [0.47003114] [0]\n",
      "72 [0.47003114] [0]\n",
      "73 [0.47003114] [0]\n",
      "74 [0.47003114] [0]\n",
      "75 [0.47003114] [0]\n",
      "76 [0.47003114] [0]\n",
      "77 [0.47003114] [0]\n",
      "78 [0.47003114] [0]\n",
      "79 [0.47003114] [0]\n",
      "80 [0.47003114] [0]\n",
      "81 [0.47003114] [0]\n",
      "82 [0.47003114] [0]\n",
      "83 [0.47003114] [0]\n",
      "84 [0.47003114] [0]\n",
      "85 [0.47003114] [0]\n",
      "86 [0.47003114] [0]\n",
      "87 [0.47003114] [0]\n",
      "88 [0.47003114] [0]\n",
      "89 [0.47003114] [0]\n",
      "90 [0.47003114] [0]\n",
      "91 [0.47003114] [0]\n",
      "92 [0.47003114] [0]\n",
      "93 [0.47003114] [0]\n",
      "94 [0.47003114] [0]\n",
      "95 [0.47003114] [0]\n",
      "96 [0.47003114] [0]\n",
      "97 [0.47003114] [0]\n",
      "98 [0.47003114] [0]\n",
      "99 [0.47003114] [0]\n"
     ]
    }
   ],
   "source": [
    "# details of a single sequence\n",
    "\n",
    "dataset_validation = tf.data.Dataset.from_tensor_slices((X_validation, Y_validation))\n",
    "dataset_validation = dataset_validation.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "for i in range(1):\n",
    "  input_batch_validation, target_batch_validation = next(iter(dataset_validation))\n",
    "\n",
    "  inp = tf.cast(input_batch_validation,dtype=tf.float32)\n",
    "  targ = target_batch_validation[0]\n",
    "\n",
    "  result = ''\n",
    "  enc_out, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "  dec_hidden = enc_hidden\n",
    "  for t in range(len(inp[0])):\n",
    "    predictions, dec_hidden, attention_weights = decoder(dec_hidden, enc_out)\n",
    "    #tf.keras.activations.softmax(predictions,-1)\n",
    "    print(t, predictions[0].numpy(), targ[t].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n250XbnjOaqP"
   },
   "source": [
    "## Restore the latest checkpoint and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UJpT9D5_OgP6",
    "outputId": "bfd7c53f-fd46-4639-ae17-b3010503ef12"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f555860ecf8>"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restoring the latest checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "WR.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
